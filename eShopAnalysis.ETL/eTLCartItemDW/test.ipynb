{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from jobs.extract.extracts import extract_mongo_brands_to_df\n",
    "from jobs.load.loads import load_brand_df_to_mssql\n",
    "\n",
    "brand_df = extract_mongo_brands_to_df()\n",
    "load_brand_df_to_mssql(brand_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from jobs.extract.extracts import extract_mongo_catalogs_to_df\n",
    "from jobs.load.loads import load_catalog_df_to_mssql\n",
    "\n",
    "category_df = extract_mongo_catalogs_to_df()\n",
    "#TODO:\n",
    "# 1. TRANSFORM DELETE NULL CATALOG NAME AND NOT SAVE TO MSSQL\n",
    "load_catalog_df_to_mssql(category_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jobs.extract.extracts import extract_mongo_subcatalogs_to_df\n",
    "from jobs.load.loads import load_subcatalog_df_to_mssql\n",
    "\n",
    "subcatalog_df = extract_mongo_subcatalogs_to_df()\n",
    "print(subcatalog_df)\n",
    "load_subcatalog_df_to_mssql(subcatalog_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jobs.extract.extracts import extract_mongo_usage_instruction_to_df\n",
    "\n",
    "usage_instruction_df = extract_mongo_usage_instruction_to_df()\n",
    "usage_instruction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "usage_instruction_df = pd.read_csv('resources/product_usage_instruction.csv')\n",
    "usage_instruction_df.dropna(inplace=True, subset=['ProductUsageInstruction'])\n",
    "\n",
    "# another approach is to use topic modeling to find the most important words in the usage instruction, \n",
    "# the most important words will be the labels for the usage instruction type\n",
    "from jobs.transform.usage_instruction_transform import *\n",
    "sublists_list = transform_preprocess_usage_instruction_df_to_sublists_tokens(usage_instruction_df)\n",
    "lemm_stemm_sublists_list = transform_lemm_stem_sublists(sublists_list)\n",
    "reduced_usage_instruction_type_df = transform_sublists_to_reduced_usage_instruction_df(lemm_stemm_sublists_list)\n",
    "# print(reduced_usage_instruction_type_df)\n",
    "from jobs.load.loads import load_usage_instruction_df_to_mssql\n",
    "load_usage_instruction_df_to_mssql(reduced_usage_instruction_type_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 04:52:02,608 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2023-12-01 04:52:02,610 - INFO - built Dictionary<149 unique tokens: ['chill', 'directly', 'drink', 'instantly', 'serve']...> from 40 documents (total 246 corpus positions)\n",
      "2023-12-01 04:52:02,611 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<149 unique tokens: ['chill', 'directly', 'drink', 'instantly', 'serve']...> from 40 documents (total 246 corpus positions)\", 'datetime': '2023-12-01T04:52:02.611929', 'gensim': '4.3.2', 'python': '3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-12-01 04:52:02,612 - INFO - discarding 129 tokens: [('drink', 2), ('instantly', 1), ('shake', 1), ('body', 1), ('wet', 1), ('immediately', 2), ('package', 1), ('dairectly', 1), ('favorite', 1), ('spice', 1)]...\n",
      "2023-12-01 04:52:02,613 - INFO - keeping 20 tokens which were in no less than 3 and no more than 20 (=50.0%) documents\n",
      "2023-12-01 04:52:02,614 - INFO - resulting dictionary: Dictionary<20 unique tokens: ['chill', 'directly', 'serve', 'boil', 'direct']...>\n",
      "2023-12-01 04:52:02,616 - INFO - using symmetric alpha at 0.125\n",
      "2023-12-01 04:52:02,617 - INFO - using symmetric eta at 0.125\n",
      "2023-12-01 04:52:02,618 - INFO - using serial LDA version on this node\n",
      "2023-12-01 04:52:02,619 - INFO - running online LDA training, 8 topics, 10 passes over the supplied corpus of 40 documents, updating every 8000 documents, evaluating every ~40 documents, iterating 10x with a convergence threshold of 0.001000\n",
      "2023-12-01 04:52:02,620 - INFO - training LDA model using 4 processes\n",
      "2023-12-01 04:52:02,920 - INFO - PROGRESS: pass 0, dispatched chunk #0 = documents up to #40/40, outstanding queue size 1\n",
      "2023-12-01 04:52:03,392 - INFO - topic #1 (0.125): 0.149*\"bread\" + 0.149*\"direct\" + 0.147*\"well\" + 0.147*\"cook\" + 0.147*\"boil\" + 0.021*\"date\" + 0.020*\"expiry\" + 0.019*\"dish\" + 0.018*\"directly\" + 0.018*\"open\"\n",
      "2023-12-01 04:52:03,393 - INFO - topic #4 (0.125): 0.226*\"direct\" + 0.104*\"open\" + 0.104*\"expiry\" + 0.087*\"date\" + 0.076*\"directly\" + 0.066*\"treatment\" + 0.062*\"milk\" + 0.060*\"heat\" + 0.032*\"dish\" + 0.025*\"eat\"\n",
      "2023-12-01 04:52:03,394 - INFO - topic #6 (0.125): 0.209*\"eat\" + 0.130*\"bread\" + 0.123*\"dish\" + 0.121*\"directly\" + 0.090*\"serve\" + 0.077*\"open\" + 0.064*\"expiry\" + 0.057*\"date\" + 0.022*\"pasta\" + 0.022*\"salad\"\n",
      "2023-12-01 04:52:03,394 - INFO - topic #7 (0.125): 0.142*\"serve\" + 0.115*\"salad\" + 0.111*\"pasta\" + 0.073*\"chill\" + 0.073*\"open\" + 0.063*\"directly\" + 0.063*\"bread\" + 0.057*\"heat\" + 0.054*\"milk\" + 0.044*\"cook\"\n",
      "2023-12-01 04:52:03,395 - INFO - topic #2 (0.125): 0.170*\"directly\" + 0.135*\"open\" + 0.135*\"chill\" + 0.112*\"cook\" + 0.105*\"dish\" + 0.072*\"well\" + 0.071*\"sauce\" + 0.071*\"pasta\" + 0.040*\"delicious\" + 0.008*\"serve\"\n",
      "2023-12-01 04:52:03,397 - INFO - topic diff=4.017790, rho=1.000000\n",
      "2023-12-01 04:52:03,402 - INFO - -4.446 per-word bound, 21.8 perplexity estimate based on a held-out corpus of 40 documents with 89 words\n",
      "2023-12-01 04:52:03,403 - INFO - PROGRESS: pass 1, dispatched chunk #0 = documents up to #40/40, outstanding queue size 1\n",
      "2023-12-01 04:52:03,406 - INFO - topic #6 (0.125): 0.215*\"eat\" + 0.143*\"bread\" + 0.138*\"dish\" + 0.124*\"directly\" + 0.082*\"serve\" + 0.078*\"open\" + 0.060*\"expiry\" + 0.050*\"date\" + 0.013*\"pasta\" + 0.013*\"salad\"\n",
      "2023-12-01 04:52:03,407 - INFO - topic #7 (0.125): 0.225*\"serve\" + 0.160*\"salad\" + 0.158*\"pasta\" + 0.089*\"chill\" + 0.085*\"bread\" + 0.033*\"open\" + 0.030*\"directly\" + 0.028*\"heat\" + 0.026*\"milk\" + 0.023*\"cook\"\n",
      "2023-12-01 04:52:03,408 - INFO - topic #3 (0.125): 0.199*\"date\" + 0.160*\"directly\" + 0.152*\"treatment\" + 0.151*\"heat\" + 0.040*\"expiry\" + 0.029*\"direct\" + 0.028*\"open\" + 0.026*\"bread\" + 0.025*\"dish\" + 0.018*\"sauce\"\n",
      "2023-12-01 04:52:03,409 - INFO - topic #2 (0.125): 0.169*\"directly\" + 0.160*\"open\" + 0.120*\"chill\" + 0.114*\"cook\" + 0.112*\"dish\" + 0.064*\"well\" + 0.064*\"sauce\" + 0.064*\"pasta\" + 0.055*\"delicious\" + 0.007*\"serve\"\n",
      "2023-12-01 04:52:03,410 - INFO - topic #5 (0.125): 0.217*\"dish\" + 0.138*\"salad\" + 0.125*\"delicious\" + 0.124*\"expiry\" + 0.122*\"date\" + 0.050*\"well\" + 0.023*\"pasta\" + 0.020*\"bread\" + 0.016*\"directly\" + 0.016*\"cook\"\n",
      "2023-12-01 04:52:03,411 - INFO - topic diff=0.540852, rho=0.703598\n",
      "2023-12-01 04:52:03,418 - INFO - -4.257 per-word bound, 19.1 perplexity estimate based on a held-out corpus of 40 documents with 89 words\n",
      "2023-12-01 04:52:03,419 - INFO - PROGRESS: pass 2, dispatched chunk #0 = documents up to #40/40, outstanding queue size 1\n",
      "2023-12-01 04:52:03,425 - INFO - topic #7 (0.125): 0.251*\"serve\" + 0.173*\"salad\" + 0.173*\"pasta\" + 0.094*\"chill\" + 0.092*\"bread\" + 0.021*\"open\" + 0.019*\"directly\" + 0.018*\"heat\" + 0.018*\"milk\" + 0.016*\"cook\"\n",
      "2023-12-01 04:52:03,425 - INFO - topic #2 (0.125): 0.169*\"directly\" + 0.165*\"open\" + 0.117*\"chill\" + 0.115*\"cook\" + 0.114*\"dish\" + 0.062*\"well\" + 0.062*\"sauce\" + 0.062*\"pasta\" + 0.059*\"delicious\" + 0.007*\"serve\"\n",
      "2023-12-01 04:52:03,426 - INFO - topic #0 (0.125): 0.229*\"directly\" + 0.124*\"heat\" + 0.096*\"sauce\" + 0.093*\"date\" + 0.093*\"milk\" + 0.065*\"boil\" + 0.063*\"treatment\" + 0.058*\"expiry\" + 0.038*\"serve\" + 0.036*\"delicious\"\n",
      "2023-12-01 04:52:03,427 - INFO - topic #5 (0.125): 0.236*\"dish\" + 0.135*\"salad\" + 0.129*\"delicious\" + 0.129*\"expiry\" + 0.128*\"date\" + 0.030*\"well\" + 0.018*\"pasta\" + 0.017*\"bread\" + 0.015*\"directly\" + 0.015*\"cook\"\n",
      "2023-12-01 04:52:03,428 - INFO - topic #1 (0.125): 0.238*\"well\" + 0.134*\"bread\" + 0.134*\"direct\" + 0.134*\"cook\" + 0.134*\"boil\" + 0.015*\"date\" + 0.015*\"expiry\" + 0.015*\"dish\" + 0.015*\"directly\" + 0.015*\"open\"\n",
      "2023-12-01 04:52:03,429 - INFO - topic diff=0.320228, rho=0.575435\n",
      "2023-12-01 04:52:03,437 - INFO - -4.189 per-word bound, 18.2 perplexity estimate based on a held-out corpus of 40 documents with 89 words\n",
      "2023-12-01 04:52:03,438 - INFO - PROGRESS: pass 3, dispatched chunk #0 = documents up to #40/40, outstanding queue size 1\n",
      "2023-12-01 04:52:03,442 - INFO - topic #3 (0.125): 0.180*\"date\" + 0.170*\"treatment\" + 0.164*\"heat\" + 0.159*\"directly\" + 0.025*\"expiry\" + 0.022*\"direct\" + 0.022*\"open\" + 0.022*\"bread\" + 0.021*\"dish\" + 0.020*\"sauce\"\n",
      "2023-12-01 04:52:03,443 - INFO - topic #0 (0.125): 0.237*\"directly\" + 0.133*\"heat\" + 0.100*\"sauce\" + 0.099*\"milk\" + 0.076*\"date\" + 0.068*\"boil\" + 0.068*\"treatment\" + 0.038*\"serve\" + 0.038*\"expiry\" + 0.037*\"delicious\"\n",
      "2023-12-01 04:52:03,443 - INFO - topic #2 (0.125): 0.169*\"directly\" + 0.167*\"open\" + 0.116*\"chill\" + 0.115*\"cook\" + 0.114*\"dish\" + 0.061*\"sauce\" + 0.061*\"well\" + 0.061*\"pasta\" + 0.060*\"delicious\" + 0.007*\"serve\"\n",
      "2023-12-01 04:52:03,444 - INFO - topic #5 (0.125): 0.243*\"dish\" + 0.133*\"salad\" + 0.131*\"delicious\" + 0.131*\"expiry\" + 0.130*\"date\" + 0.022*\"well\" + 0.016*\"pasta\" + 0.016*\"bread\" + 0.015*\"directly\" + 0.015*\"cook\"\n",
      "2023-12-01 04:52:03,445 - INFO - topic #4 (0.125): 0.241*\"expiry\" + 0.239*\"date\" + 0.205*\"direct\" + 0.108*\"open\" + 0.015*\"directly\" + 0.015*\"treatment\" + 0.014*\"milk\" + 0.014*\"heat\" + 0.013*\"dish\" + 0.013*\"eat\"\n",
      "2023-12-01 04:52:03,446 - INFO - topic diff=0.206847, rho=0.498755\n",
      "2023-12-01 04:52:03,454 - INFO - -4.152 per-word bound, 17.8 perplexity estimate based on a held-out corpus of 40 documents with 89 words\n",
      "2023-12-01 04:52:03,455 - INFO - PROGRESS: pass 4, dispatched chunk #0 = documents up to #40/40, outstanding queue size 1\n",
      "2023-12-01 04:52:03,460 - INFO - topic #0 (0.125): 0.242*\"directly\" + 0.138*\"heat\" + 0.104*\"sauce\" + 0.103*\"milk\" + 0.071*\"boil\" + 0.071*\"treatment\" + 0.062*\"date\" + 0.038*\"serve\" + 0.038*\"delicious\" + 0.038*\"pasta\"\n",
      "2023-12-01 04:52:03,461 - INFO - topic #5 (0.125): 0.263*\"dish\" + 0.142*\"salad\" + 0.141*\"delicious\" + 0.107*\"expiry\" + 0.106*\"date\" + 0.020*\"well\" + 0.017*\"pasta\" + 0.016*\"bread\" + 0.016*\"directly\" + 0.016*\"cook\"\n",
      "2023-12-01 04:52:03,463 - INFO - topic #1 (0.125): 0.247*\"well\" + 0.133*\"bread\" + 0.133*\"direct\" + 0.133*\"cook\" + 0.133*\"boil\" + 0.015*\"date\" + 0.015*\"expiry\" + 0.015*\"dish\" + 0.015*\"directly\" + 0.015*\"open\"\n",
      "2023-12-01 04:52:03,464 - INFO - topic #2 (0.125): 0.169*\"directly\" + 0.168*\"open\" + 0.115*\"chill\" + 0.115*\"cook\" + 0.115*\"dish\" + 0.061*\"sauce\" + 0.061*\"well\" + 0.061*\"pasta\" + 0.060*\"delicious\" + 0.007*\"serve\"\n",
      "2023-12-01 04:52:03,465 - INFO - topic #4 (0.125): 0.280*\"expiry\" + 0.278*\"date\" + 0.176*\"direct\" + 0.093*\"open\" + 0.012*\"directly\" + 0.012*\"treatment\" + 0.011*\"milk\" + 0.011*\"heat\" + 0.011*\"dish\" + 0.011*\"eat\"\n",
      "2023-12-01 04:52:03,465 - INFO - topic diff=0.146336, rho=0.446322\n",
      "2023-12-01 04:52:03,472 - INFO - -4.118 per-word bound, 17.4 perplexity estimate based on a held-out corpus of 40 documents with 89 words\n",
      "2023-12-01 04:52:03,473 - INFO - PROGRESS: pass 5, dispatched chunk #0 = documents up to #40/40, outstanding queue size 1\n",
      "2023-12-01 04:52:03,477 - INFO - topic #6 (0.125): 0.225*\"eat\" + 0.152*\"bread\" + 0.152*\"dish\" + 0.148*\"directly\" + 0.081*\"serve\" + 0.081*\"open\" + 0.029*\"expiry\" + 0.023*\"date\" + 0.009*\"pasta\" + 0.009*\"salad\"\n",
      "2023-12-01 04:52:03,478 - INFO - topic #3 (0.125): 0.176*\"date\" + 0.173*\"treatment\" + 0.169*\"heat\" + 0.164*\"directly\" + 0.021*\"expiry\" + 0.020*\"direct\" + 0.020*\"open\" + 0.020*\"bread\" + 0.020*\"dish\" + 0.020*\"sauce\"\n",
      "2023-12-01 04:52:03,478 - INFO - topic #5 (0.125): 0.282*\"dish\" + 0.151*\"salad\" + 0.150*\"delicious\" + 0.081*\"expiry\" + 0.081*\"date\" + 0.020*\"well\" + 0.017*\"pasta\" + 0.017*\"bread\" + 0.017*\"directly\" + 0.017*\"cook\"\n",
      "2023-12-01 04:52:03,480 - INFO - topic #4 (0.125): 0.302*\"expiry\" + 0.299*\"date\" + 0.160*\"direct\" + 0.085*\"open\" + 0.010*\"directly\" + 0.010*\"treatment\" + 0.010*\"milk\" + 0.010*\"heat\" + 0.010*\"dish\" + 0.010*\"eat\"\n",
      "2023-12-01 04:52:03,481 - INFO - topic #2 (0.125): 0.183*\"directly\" + 0.161*\"open\" + 0.110*\"chill\" + 0.110*\"cook\" + 0.110*\"dish\" + 0.079*\"delicious\" + 0.058*\"sauce\" + 0.058*\"pasta\" + 0.058*\"well\" + 0.006*\"serve\"\n",
      "2023-12-01 04:52:03,481 - INFO - topic diff=0.115054, rho=0.407570\n",
      "2023-12-01 04:52:03,488 - INFO - -4.083 per-word bound, 16.9 perplexity estimate based on a held-out corpus of 40 documents with 89 words\n",
      "2023-12-01 04:52:03,489 - INFO - PROGRESS: pass 6, dispatched chunk #0 = documents up to #40/40, outstanding queue size 1\n",
      "2023-12-01 04:52:03,494 - INFO - topic #4 (0.125): 0.313*\"expiry\" + 0.310*\"date\" + 0.152*\"direct\" + 0.080*\"open\" + 0.009*\"directly\" + 0.009*\"treatment\" + 0.009*\"milk\" + 0.009*\"heat\" + 0.009*\"dish\" + 0.009*\"eat\"\n",
      "2023-12-01 04:52:03,494 - INFO - topic #6 (0.125): 0.227*\"eat\" + 0.154*\"bread\" + 0.154*\"dish\" + 0.151*\"directly\" + 0.082*\"serve\" + 0.082*\"open\" + 0.023*\"expiry\" + 0.019*\"date\" + 0.009*\"pasta\" + 0.009*\"salad\"\n",
      "2023-12-01 04:52:03,496 - INFO - topic #5 (0.125): 0.295*\"dish\" + 0.158*\"salad\" + 0.157*\"delicious\" + 0.062*\"date\" + 0.062*\"expiry\" + 0.019*\"well\" + 0.018*\"pasta\" + 0.018*\"bread\" + 0.018*\"directly\" + 0.018*\"cook\"\n",
      "2023-12-01 04:52:03,497 - INFO - topic #2 (0.125): 0.190*\"directly\" + 0.158*\"open\" + 0.108*\"chill\" + 0.107*\"cook\" + 0.107*\"dish\" + 0.089*\"delicious\" + 0.057*\"sauce\" + 0.057*\"pasta\" + 0.057*\"well\" + 0.006*\"serve\"\n",
      "2023-12-01 04:52:03,497 - INFO - topic #0 (0.125): 0.235*\"directly\" + 0.148*\"heat\" + 0.112*\"sauce\" + 0.112*\"milk\" + 0.076*\"treatment\" + 0.076*\"boil\" + 0.052*\"date\" + 0.041*\"serve\" + 0.040*\"pasta\" + 0.040*\"cook\"\n",
      "2023-12-01 04:52:03,498 - INFO - topic diff=0.083380, rho=0.377426\n",
      "2023-12-01 04:52:03,506 - INFO - -4.062 per-word bound, 16.7 perplexity estimate based on a held-out corpus of 40 documents with 89 words\n",
      "2023-12-01 04:52:03,506 - INFO - PROGRESS: pass 7, dispatched chunk #0 = documents up to #40/40, outstanding queue size 1\n",
      "2023-12-01 04:52:03,510 - INFO - topic #4 (0.125): 0.320*\"expiry\" + 0.317*\"date\" + 0.147*\"direct\" + 0.078*\"open\" + 0.009*\"directly\" + 0.009*\"treatment\" + 0.009*\"milk\" + 0.009*\"heat\" + 0.009*\"dish\" + 0.009*\"eat\"\n",
      "2023-12-01 04:52:03,513 - INFO - topic #1 (0.125): 0.249*\"well\" + 0.132*\"bread\" + 0.132*\"direct\" + 0.132*\"cook\" + 0.132*\"boil\" + 0.015*\"date\" + 0.015*\"expiry\" + 0.015*\"dish\" + 0.015*\"directly\" + 0.015*\"open\"\n",
      "2023-12-01 04:52:03,514 - INFO - topic #3 (0.125): 0.176*\"date\" + 0.173*\"treatment\" + 0.170*\"heat\" + 0.165*\"directly\" + 0.020*\"expiry\" + 0.020*\"direct\" + 0.020*\"open\" + 0.020*\"bread\" + 0.020*\"dish\" + 0.020*\"sauce\"\n",
      "2023-12-01 04:52:03,515 - INFO - topic #7 (0.125): 0.270*\"serve\" + 0.184*\"salad\" + 0.184*\"pasta\" + 0.098*\"chill\" + 0.097*\"bread\" + 0.012*\"open\" + 0.011*\"directly\" + 0.011*\"heat\" + 0.011*\"milk\" + 0.011*\"cook\"\n",
      "2023-12-01 04:52:03,516 - INFO - topic #0 (0.125): 0.235*\"directly\" + 0.151*\"heat\" + 0.113*\"sauce\" + 0.113*\"milk\" + 0.078*\"treatment\" + 0.077*\"boil\" + 0.050*\"date\" + 0.041*\"serve\" + 0.041*\"pasta\" + 0.041*\"cook\"\n",
      "2023-12-01 04:52:03,517 - INFO - topic diff=0.063485, rho=0.353112\n",
      "2023-12-01 04:52:03,523 - INFO - -4.052 per-word bound, 16.6 perplexity estimate based on a held-out corpus of 40 documents with 89 words\n",
      "2023-12-01 04:52:03,525 - INFO - PROGRESS: pass 8, dispatched chunk #0 = documents up to #40/40, outstanding queue size 1\n",
      "2023-12-01 04:52:03,531 - INFO - topic #1 (0.125): 0.250*\"well\" + 0.132*\"bread\" + 0.132*\"cook\" + 0.132*\"direct\" + 0.132*\"boil\" + 0.015*\"date\" + 0.015*\"expiry\" + 0.015*\"dish\" + 0.015*\"directly\" + 0.015*\"open\"\n",
      "2023-12-01 04:52:03,532 - INFO - topic #2 (0.125): 0.197*\"directly\" + 0.155*\"open\" + 0.105*\"chill\" + 0.105*\"cook\" + 0.105*\"dish\" + 0.097*\"delicious\" + 0.056*\"pasta\" + 0.056*\"sauce\" + 0.056*\"well\" + 0.006*\"serve\"\n",
      "2023-12-01 04:52:03,533 - INFO - topic #3 (0.125): 0.175*\"date\" + 0.173*\"treatment\" + 0.171*\"heat\" + 0.168*\"directly\" + 0.020*\"expiry\" + 0.020*\"direct\" + 0.020*\"open\" + 0.020*\"bread\" + 0.020*\"dish\" + 0.020*\"sauce\"\n",
      "2023-12-01 04:52:03,534 - INFO - topic #7 (0.125): 0.271*\"serve\" + 0.184*\"pasta\" + 0.184*\"salad\" + 0.098*\"chill\" + 0.098*\"bread\" + 0.011*\"open\" + 0.011*\"directly\" + 0.011*\"heat\" + 0.011*\"milk\" + 0.011*\"cook\"\n",
      "2023-12-01 04:52:03,535 - INFO - topic #5 (0.125): 0.312*\"dish\" + 0.166*\"salad\" + 0.165*\"delicious\" + 0.040*\"date\" + 0.040*\"expiry\" + 0.019*\"well\" + 0.019*\"pasta\" + 0.019*\"bread\" + 0.018*\"directly\" + 0.018*\"cook\"\n",
      "2023-12-01 04:52:03,536 - INFO - topic diff=0.051592, rho=0.332964\n",
      "2023-12-01 04:52:03,543 - INFO - -4.042 per-word bound, 16.5 perplexity estimate based on a held-out corpus of 40 documents with 89 words\n",
      "2023-12-01 04:52:03,544 - INFO - PROGRESS: pass 9, dispatched chunk #0 = documents up to #40/40, outstanding queue size 1\n",
      "2023-12-01 04:52:03,548 - INFO - topic #4 (0.125): 0.326*\"expiry\" + 0.323*\"date\" + 0.142*\"direct\" + 0.075*\"open\" + 0.008*\"directly\" + 0.008*\"treatment\" + 0.008*\"milk\" + 0.008*\"heat\" + 0.008*\"dish\" + 0.008*\"delicious\"\n",
      "2023-12-01 04:52:03,549 - INFO - topic #1 (0.125): 0.250*\"well\" + 0.132*\"cook\" + 0.132*\"bread\" + 0.132*\"direct\" + 0.132*\"boil\" + 0.015*\"date\" + 0.015*\"expiry\" + 0.015*\"dish\" + 0.015*\"directly\" + 0.015*\"open\"\n",
      "2023-12-01 04:52:03,550 - INFO - topic #3 (0.125): 0.175*\"date\" + 0.173*\"treatment\" + 0.171*\"heat\" + 0.168*\"directly\" + 0.020*\"expiry\" + 0.020*\"direct\" + 0.020*\"open\" + 0.020*\"bread\" + 0.020*\"dish\" + 0.020*\"sauce\"\n",
      "2023-12-01 04:52:03,551 - INFO - topic #6 (0.125): 0.230*\"eat\" + 0.156*\"bread\" + 0.156*\"dish\" + 0.156*\"directly\" + 0.083*\"serve\" + 0.083*\"open\" + 0.014*\"expiry\" + 0.012*\"date\" + 0.009*\"pasta\" + 0.009*\"salad\"\n",
      "2023-12-01 04:52:03,552 - INFO - topic #2 (0.125): 0.198*\"directly\" + 0.154*\"open\" + 0.105*\"chill\" + 0.105*\"cook\" + 0.105*\"dish\" + 0.099*\"delicious\" + 0.055*\"pasta\" + 0.055*\"sauce\" + 0.055*\"well\" + 0.006*\"serve\"\n",
      "2023-12-01 04:52:03,553 - INFO - topic diff=0.040815, rho=0.315912\n",
      "2023-12-01 04:52:03,561 - INFO - -4.041 per-word bound, 16.5 perplexity estimate based on a held-out corpus of 40 documents with 89 words\n",
      "2023-12-01 04:52:03,580 - INFO - LdaMulticore lifecycle event {'msg': 'trained LdaMulticore<num_terms=20, num_topics=8, decay=0.5, chunksize=2000> in 0.96s', 'datetime': '2023-12-01T04:52:03.580176', 'gensim': '4.3.2', 'python': '3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-12-01 04:52:03,586 - INFO - Connected to MSSQL database\n",
      "d:\\Bi\\BiDocument\\HK1_2024\\TLCN\\eShopAnalysis\\TLCN-eShopAnalysis\\eShopAnalysis.ETL\\eTLCartItemDW\\jobs\\load\\loads.py:77: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_usage_instruction = pd.read_sql_query(query, mssql_cursor.connection)\n",
      "2023-12-01 04:52:03,603 - INFO - Connection to MSSQL closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: directly, heat, sauce, milk, treatment\n",
      "Topic #1: well, cook, bread, direct, boil\n",
      "Topic #2: directly, open, chill, cook, dish\n",
      "Topic #3: date, treatment, heat, directly, expiry\n",
      "Topic #4: expiry, date, direct, open, directly\n",
      "Topic #5: dish, salad, delicious, date, expiry\n",
      "Topic #6: eat, bread, dish, directly, serve\n",
      "Topic #7: serve, pasta, salad, chill, bread\n",
      "{0: 'directly, heat, sauce, milk, treatment', 1: 'well, cook, bread, direct, boil', 2: 'directly, open, chill, cook, dish', 3: 'date, treatment, heat, directly, expiry', 4: 'expiry, date, direct, open, directly', 5: 'dish, salad, delicious, date, expiry', 6: 'eat, bread, dish, directly, serve', 7: 'serve, pasta, salad, chill, bread'}\n",
      "                  UsageInstructionTypeName\n",
      "0   directly, heat, sauce, milk, treatment\n",
      "1          well, cook, bread, direct, boil\n",
      "2        directly, open, chill, cook, dish\n",
      "3  date, treatment, heat, directly, expiry\n",
      "4     expiry, date, direct, open, directly\n",
      "5     dish, salad, delicious, date, expiry\n",
      "6        eat, bread, dish, directly, serve\n",
      "7        serve, pasta, salad, chill, bread\n",
      "   UsageInstructionTypeId                 UsageInstructionTypeName\n",
      "0                       0   directly, heat, sauce, milk, treatment\n",
      "1                       1          well, cook, bread, direct, boil\n",
      "2                       2        directly, open, chill, cook, dish\n",
      "3                       3  date, treatment, heat, directly, expiry\n",
      "4                       4     expiry, date, direct, open, directly\n",
      "5                       5     dish, salad, delicious, date, expiry\n",
      "6                       6        eat, bread, dish, directly, serve\n",
      "7                       7        serve, pasta, salad, chill, bread\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "usage_instruction_df = pd.read_csv('resources/product_usage_instruction.csv')\n",
    "usage_instruction_df.dropna(inplace=True, subset=['ProductUsageInstruction'])\n",
    "\n",
    "from jobs.transform.usage_instruction_transform import transform_to_usage_instruction_df_with_topic_and_word_representation\n",
    "from jobs.load.loads import load_usage_instruction_df_to_mssql\n",
    "usage_instruction_df_with_topic_and_wp = transform_to_usage_instruction_df_with_topic_and_word_representation(usage_instruction_df, 8)\n",
    "print(usage_instruction_df_with_topic_and_wp)\n",
    "# how to save the model to evaluate the new data: https://stackoverflow.com/a/22034166\n",
    "# how to use this model and evaluate the new data: https://datascience.stackexchange.com/a/107383\n",
    "# another document with all the above: https://medium.com/@rayhantithokharisma/latent-dirichlet-allocation-topic-modelling-with-online-learning-feature-5051ca9df749\n",
    "load_usage_instruction_df_to_mssql(usage_instruction_df_with_topic_and_wp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
